#include <loki/lokilib.h>
#include <loki/scratchpad.h>
#include "setting.h"

#define MC  32
#define KC  64
#define NC  128

#define MR  4
#define NR  4
#define MATRIX_NUM_CORE 4
// typedef int Dtype;
//
//  Local buffers for storing panels from A, B and C
//
static Dtype _A[MC*KC];
static Dtype _B[KC*NC];
// static Dtype _C[MR*NR];

//
//  Packing complete panels from A (i.e. without padding)
//
static void
pack_MRxk(int k, const Dtype *A, int incRowA, int incColA,
          Dtype *buffer)
{
    Dtype* limit = &buffer[k*MR];
    /*
    * the below is the original code
    */
    // for (; buffer < limit; buffer += MR) {
    //     for (int i=0; i<MR; ++i) {
    //         buffer[i] = A[i*incRowA];
    //     }
    //     // buffer += MR;
    //     A      += incColA;
    // }
    /*
    * the below is an attempt to load in parallel, only work without loki_sync somehow
    */
    asm volatile(
      "fetchr.eop 0f\n"
      "0: \n"

      "ldw 0x0(%0) -> 1 \n"
      "addu r28, %0, %3 \n"
      "ldw 0x0(r28) -> 1 \n"
      "addu r28, r28, %3 \n"
      "ldw 0x0(r28) -> 1 \n"
      "addu r28, r28, %3 \n"
      "ldw 0x0(r28) -> 1 \n"

      "setlt.p r0, %1, %2 \n"     // compare if first limit has reached
      "addui %0, %0, 0x04 \n"
      "psel.fetchr 0b, 1f\n" //? potential source of packet miss ?

      "stw r2, 0x0(%1) -> 1 \n"
      "stw r2, 0x4(%1) -> 1 \n"
      "stw r2, 0x8(%1) -> 1 \n"
      "stw r2, 0xc(%1) -> 1 \n"
      "addui.eop %1, %1, 0x10 \n"     // increment buffer
      "1: \n"
      : "+&r"(A), "+&r"(buffer)
      : "r"(limit), "r"(incRowA*4)
      : "r28"
      );  
}

//
//  Packing panels from A with padding if required
//
static void
pack_A(int mc, int kc, const Dtype *A, int incRowA, int incColA,
       Dtype *buffer)
{
    // fprintf(stderr, "pack A starts \n");
    int mp  = mc / MR;
    int _mr = mc % MR;

    int i, j;

    for (i=0; i<mp; ++i) {
        pack_MRxk(kc, A, incRowA, incColA, buffer);
        buffer += kc*MR;
        A      += MR*incRowA;
    }
    if (_mr>0) {
        for (j=0; j<kc; ++j) {
            for (i=0; i<_mr; ++i) {
                buffer[i] = A[i*incRowA];
            }
            for (i=_mr; i<MR; ++i) {
                buffer[i] = 0;
            }
            buffer += MR;
            A      += incColA;
        }
    }
    fprintf(stderr, "pack A ends \n");
}

//
//  Packing complete panels from B (i.e. without padding)
//
static void
pack_kxNR(int k, const Dtype *B, int incRowB, int incColB,
          Dtype *buffer)
{
    Dtype * limit = &B[k*incRowB];
    /*
    * the below is the original version
    */
    // for (; B<limit; B+=incRowB) {
    //     for (int j=0; j<NR; ++j) {
    //         buffer[j] = B[j*incColB];
    //     }
    //     buffer += NR;
    //     // B      += incRowB;
    // }
    /*
    *  the below is the optimized version
    */
    asm volatile(
      "fetchr.eop 0f\n"
      "0: \n"
      "ldw 0x0(%0) -> 1 \n"
      "ldw 0x4(%0) -> 1 \n"
      "ldw 0x8(%0) -> 1 \n"
      "ldw 0xc(%0) -> 1 \n"

      "setlt.p r0, %0, %2 \n"
      "addu %0, %0, %3 \n"
      "psel.fetchr 0b, 1f\n"

      "stw r2, 0x0(%1) -> 1 \n"
      "stw r2, 0x4(%1) -> 1 \n"
      "stw r2, 0x8(%1) -> 1 \n"
      "stw r2, 0xc(%1) -> 1 \n"
      "addui.eop %1, %1, 0x10 \n"     // increment buffer
      "1: \n"
      : "+&r"(B), "+&r"(buffer)
      : "r"(limit), "r"(incRowB*4)
      :
      );
}



//
//  Packing panels from B with padding if required
//
static void
pack_B(int kc, int nc, const Dtype *B, int incRowB, int incColB,
       Dtype *buffer)
{
      // fprintf(stderr, "pack B \n");
    // int core = get_core_id();
    // if(core == 0){
      int np  = nc / NR;
      int _nr = nc % NR;

      int i, j;


        // buffer += kc*NR*core;
        // B += kc*NR*core;

        for (j=0; j<np; j+=1) {
            pack_kxNR(kc, B, incRowB, incColB, buffer);
            buffer += kc*NR;
            B      += NR*incColB;
        }
        if (_nr>0) {
            for (i=0; i<kc; ++i) {
                for (j=0; j<_nr; ++j) {
                    buffer[j] = B[j*incColB];
                }
                for (j=_nr; j<NR; ++j) {
                    buffer[j] = 0;
                }
                buffer += NR;
                B      += incRowB;
            }
        }
    // }
    // loki_sync(MATRIX_NUM_CORE);
    // fprintf(stderr, "pack B ends\n");
}


static void
dgemm_micro_kernel( 
                   )
{

    asm volatile (
      // initialize 16 registers to hold intermediate values
      // "fetchr.eop 0f \n"
      // "0:"
      "scratchwri r9, 9 \n"
      "fetchr 0f \n"              // prefetching
      "and r10, r0, r10 \n"  // AB00
      "and r11, r0, r11 \n"  // AB10
      "and r12, r0, r12 \n"  // AB20
      "and r13, r0, r13 \n"  // AB30
      
      "and r14, r0, r14 \n"  // AB01
      "and r15, r0, r15 \n"  // AB11
      "and r16, r0, r16 \n"  // AB21
      "and r17, r0, r17 \n"  // AB31
      "and r18, r0, r18 \n"  // AB02
      "and r19, r0, r19 \n"  // AB12
      "and r20, r0, r20 \n"  // AB22
      "and r21, r0, r21 \n"  // AB32
      
      "and r22, r0, r22 \n"  // AB03
      "and r23, r0, r23 \n"  // AB13
      "and r24, r0, r24 \n"  // AB23
      "and r25, r0, r25 \n"  // AB33
      "scratchrdi r27, 1 \n"    // r27 now hold the value of A
      "scratchrdi.eop r28, 0 \n"  // r28 now hold the value of B

      /* check the loop end condition */
      "0: \n"
        // update the first column
        "ldw 0x0(r27) -> 2 \n"   // load the value of A[0]
        "ldw 0x4(r27) -> 2 \n"    // load the value of A[1]
        "ldw 0x8(r27) -> 2 \n"    // load the value of A[2]
        "ldw 0xc(r27) -> 2 \n"    // load the value of A[3]
        "or r8, r0, r3 \n"        // r8 permenantly hold the value of A[0]       
        "or r26, r0, r3 \n"    // r26 permenantly hold the value of A[1]
        "or r30, r0, r3 \n"    // r30 permenantly hold the value of A[2]
        "or r9, r0, r3 \n"
        "ldw 0x0(r28) -> 2 \n"    // load the value of B[0]
        "ldw 0x4(r28) -> 2 \n"    // load the value of B[1]
        "ldw 0x8(r28) -> 2 \n"    // load the value of B[2]
        "ldw 0xc(r28) -> 2 \n"    // load the value of B[3]

        // check loop condition for next packet fetching \n"
        "scratchrdi r29, 2 \n"        // load the value of limit

        "addui r28, r28, 0x10 \n"     // sincrement B        
        "setlt.p r0, r28, r29 \n"     // compare if first limit has reached
        "addui r27, r27, 0x10 \n"     // increment A
        "psel.fetchr 0b, 1f\n" //? potential source of packet miss ?
        // "addu r29, r29, r29 \n"
        // "addu r29, r29, r29 \n"
        "or r29, r3, r0 \n"       // read the value of B[0] from channel
        "mullw r31, r29, r8 \n"
        "addu r10, r10, r31 \n"
        "mullw r31, r29, r26\n"
        "addu r11, r11, r31 \n"
        "mullw r31, r29, r30\n"
        "addu r12, r12, r31 \n"
        "mullw r31, r29, r9\n"  // r9 permenantly hold the value of A[3]
        "addu r13, r13, r31 \n"
        // update the 2nd column
        "or r29, r3, r0 \n"
        "mullw r31, r29, r8\n"
        "addu r14, r14, r31 \n"
        "mullw r31, r29, r26\n"
        "addu r15, r15, r31 \n"
        
        "mullw r31, r29, r30\n"
        "addu r16, r16, r31 \n"
        "mullw r31, r29, r9 \n"
        "addu r17, r17, r31 \n"
        // update the third column
        "or r29, r3, r0    \n"
        "mullw r31, r29, r8\n"
        "addu r18, r18, r31 \n"
        "mullw r31, r29, r26\n"
        "addu r19, r19, r31 \n"
        "mullw r31, r29, r30\n"
        "addu r20, r20, r31 \n"
        "mullw r31, r29, r9\n"
        "addu r21, r21, r31 \n"

        // update the fourth column
        "or r29, r3, r0 \n"
        
        "mullw r31, r29, r8\n"
        "addu r22, r22, r31 \n"
        "mullw r31, r29, r26\n"
        "addu r23, r23, r31 \n"
        "mullw r31, r29, r30\n"
        "addu r24, r24, r31 \n"
        "mullw r31, r29, r9\n"
        "addu.eop r25, r25, r31 \n"


      "1: \n"      
      // "srai r10, r10, 0x0a \n"
      // "srai r11, r11, 0x0a \n"
      // "srai r12, r12, 0x0a \n"
      // "srai r13, r13, 0x0a \n"
      // "srai r14, r14, 0x0a \n"
      // "srai r15, r15, 0x0a \n"
      // "srai r16, r16, 0x0a \n"
      // "srai r17, r17, 0x0a \n"
      // "srai r18, r18, 0x0a \n"
      // "srai r19, r19, 0x0a \n"
      // "srai r20, r20, 0x0a \n"
      // "srai r21, r21, 0x0a \n"
      // "srai r22, r22, 0x0a \n"
      // "srai r23, r23, 0x0a \n"
      // "srai r24, r24, 0x0a \n"
      // "srai r25, r25, 0x0a \n"
      
      "scratchrdi r27, 7 \n"  // load beta
      "seteq.p r0, r27, r0 \n"  // set p if beta is 0
      "scratchrdi r9, 9 \n"        // restore frame pointer      
      "psel.fetchr.eop 0f, 1f\n"

      "0: \n"
      "fetchr 2f \n"
      "scratchwri r10, 0 \n"
      "scratchwri r11, 1 \n"
      "scratchwri r12, 2 \n"
      "scratchwri r13, 3 \n"
      "scratchwri r14, 4 \n"
      "scratchwri r15, 5 \n"
      "scratchwri r16, 6 \n"
      "scratchwri r17, 7 \n"
      "scratchwri r18, 8 \n"
      "scratchwri r19, 9 \n"
      "scratchwri r20, 10 \n"
      "scratchwri r21, 11 \n"
      "scratchwri r22, 12 \n"
      "scratchwri r23, 13 \n"
      "scratchwri r24, 14 \n"
      "scratchwri.eop r25, 15 \n"

      "1: \n"
      "scratchrdi r28, 3 \n"  // r28 stores the address of AB
      "scratchrdi r30, 5 \n"  // r30 incRowC
      "fetchr 2f \n"

      "ldadd r10, r28, 0x00 -> 2 \n"
      "ldadd r14, r28, 0x04 -> 2 \n"
      "ldadd r18, r28, 0x08 -> 2 \n"
      "ldadd r22, r28, 0x0c -> 2 \n"
      "or r0, r3, r0 \n"
      "or r0, r3, r0 \n"
      "or r0, r3, r0 \n"
      "or r0, r3, r0 \n"

      "addu r28, r28, r30 \n"

      "ldadd r11, r28, 0x00 -> 2 \n"
      "ldadd r15, r28, 0x04 -> 2 \n"
      "ldadd r19, r28, 0x08 -> 2 \n"
      "ldadd r23, r28, 0x0c -> 2 \n"

      "or r0, r3, r0 \n"
      "or r0, r3, r0 \n"
      "or r0, r3, r0 \n"
      "or r0, r3, r0 \n"

      "addu r28, r28, r30 \n"

      "ldadd r12, r28, 0x00 -> 2 \n"
      "ldadd r16, r28, 0x04 -> 2 \n"
      "ldadd r20, r28, 0x08 -> 2 \n"
      "ldadd r24, r28, 0x0c -> 2 \n"
      "or r0, r3, r0 \n"
      "or r0, r3, r0 \n"
      "or r0, r3, r0 \n"
      "or r0, r3, r0 \n" 

      "addu r28, r28, r30 \n"

      "ldadd r13, r28, 0x00 -> 2 \n"
      "ldadd r17, r28, 0x04 -> 2 \n"
      "ldadd r21, r28, 0x08 -> 2 \n"
      "ldadd r25, r28, 0x0c -> 2 \n"
     
      "or r0, r3, r0 \n"
      "or r0, r3, r0 \n"
      "or r0, r3, r0 \n"
      "or.eop r0, r3, r0 \n"

      // "ldw 0x0(r28) -> 1 \n"
      // "ldw 0x4(r28) -> 2 \n"
      // "addu r10, r2, r10 \n"
      // "ldw 0x8(r28) -> 1 \n"
      // "stw r10, 0x00(r28) -> 1 \n"       
      // "addu r14, r3, r14 \n"
      // "ldw 0xc(r28) -> 2 \n"
      // "stw r14, 0x04(r28) -> 1 \n"
      // "addu r18, r2, r18 \n"
      // "stw r18, 0x08(r28) -> 1 \n"
      // "addu r22, r3, r22 \n"
      // "stw r22, 0x0c(r28) -> 1 \n"
      // "addu r28, r28, r30 \n"
      // "ldw 0x0(r28) -> 1 \n"
      // "ldw 0x4(r28) -> 2 \n"
      // "addu r11, r2, r11 \n"
      // "ldw 0x8(r28) -> 1 \n"
      // "stw r11, 0x00(r28) -> 1 \n"       
      // "addu r15, r3, r15 \n"
      // "ldw 0xc(r28) -> 2 \n"
      // "stw r15, 0x04(r28) -> 1 \n"
      // "addu r19, r2, r19 \n"
      // "stw r19, 0x08(r28) -> 1 \n"
      // "addu r23, r3, r23 \n"
      // "stw r23, 0x0c(r28) -> 1 \n"
      // "addu r28, r28, r30 \n"
      // "ldw 0x0(r28) -> 1 \n"
      // "ldw 0x4(r28) -> 2 \n"
      // "addu r12, r2, r12 \n"
      // "ldw 0x8(r28) -> 1 \n"
      // "stw r12, 0x00(r28) -> 1 \n"       
      // "addu r16, r3, r16 \n"
      // "ldw 0xc(r28) -> 2 \n"
      // "stw r16, 0x04(r28) -> 1 \n"
      // "addu r20, r2, r20 \n"
      // "stw r20, 0x08(r28) -> 1 \n"
      // "addu r24, r3, r24 \n"
      // "stw r24, 0x0c(r28) -> 1 \n"
      // "addu r28, r28, r30 \n"
      // "ldw 0x0(r28) -> 1 \n"
      // "ldw 0x4(r28) -> 2 \n"
      // "addu r13, r2, r13 \n"
      // "ldw 0x8(r28) -> 1 \n"
      // "stw r13, 0x00(r28) -> 1 \n"       
      // "addu r17, r3, r17 \n"
      // "ldw 0xc(r28) -> 2 \n"
      // "stw r17, 0x04(r28) -> 1 \n"
      // "addu r21, r2, r21 \n"
      // "stw r21, 0x08(r28) -> 1 \n"
      // "addu r25, r3, r25 \n"
      // "stw.eop r25, 0x0c(r28) -> 1 \n"


      "2:"      
      :
      :
      : 
        "r10", "r11", "r12", "r13",
        "r14", "r15", "r16", "r17",
        "r18", "r19", "r20", "r21",
        "r22", "r23", "r24", "r25",
        
        "r27", "r28", "r29" ,"r31",

        "r9", "r8", "r26", "r30"
    );
}



//
//  Macro Kernel for the multiplication of blocks of A and B.  We assume that
//  these blocks were previously packed to buffers _A and _B.
//
__attribute__ ((noinline)) static void
dgemm_macro_kernel(int     mc,
                   int     nc,
                   int     kc,
                   Dtype  *C,
                   Dtype  *B,
                   Dtype  *A,
                   int     incRowC
                   // int     incColC
                   )
{
    uint core = get_core_id() + 8*tile2int(get_tile_id());
    int mp = (mc+MR-1) / MR;
    int np = (nc+NR-1) / NR;

    int _mr = mc % MR;
    int _nr = nc % NR;
    // int _kc_rem = kc % 4;
    // int _kc = kc - _kc_rem;

    int mr, nr;
    int i, j;


    for (j=core; j<np; j+=MATRIX_NUM_CORE) {
        nr    = (j!=np-1 || _nr==0) ? NR : _nr;
        for (i=0; i<mp; i++) {
            mr    = (i!=mp-1 || _mr==0) ? MR : _mr;

            if (mr==MR && nr==NR) {

                        scratchpad_write(0, &B[j*kc*NR]);     // index 0 stores the address of B
                        scratchpad_write(1, &A[i*kc*MR]);     // index 1 stores the address of A
                        scratchpad_write(3, &C[i*MR*incRowC+j*NR]);     // index 3 stores the address of AB
                        scratchpad_write(5, incRowC*4);   // integer of size 4 byte
                        // scratchpad_write(2, &_B[j*kc*NR+_kc*NR]); // index 2 stores the upper bound
                        scratchpad_write(2, &B[(j+1)*kc*NR]);
                        scratchpad_write(7, 1);    
                        // unsigned long instr_count = get_instruction_count();
                        // unsigned long cycle_count = get_cycle_count();

                        // fprintf(stderr, "\n");
                        dgemm_micro_kernel();
                          // cycle_count = get_cycle_count() - cycle_count;
                     
                          // instr_count = get_instruction_count() - instr_count;
                          // if(core == 0)
                            // fprintf(stderr, "takes %lu cycle %lu instr to complete microkernel with kc = %d \n", cycle_count, instr_count, kc);
                          // instr_count = get_instruction_count() - instr_count;
                          // cycle_count = get_cycle_count() - cycle_count;
                          // fprintf(stderr, "takes %lu cycle to complete microkernel\n", cycle_count);
                          // fprintf(stderr, "takes %lu instructions to complete microkernel\n", instr_count);
                          // fprintf(stderr, "kc is %d \n", kc);
                        // int a, b;
                        // Dtype* _C = &C[i*MR*incRowC+j*NR*incColC];
                        // for (a=0; a<nr; ++a) {
                        //     for (b=0; b<mr; ++b) {
                        //         _C[b*incRowC+a*incColC] += scratchpad_read(b+a*MR);
                        //     }
                        // }

            } else {
                        scratchpad_write(0, &B[j*kc*NR]);     // index 0 stores the address of B
                        scratchpad_write(1, &A[i*kc*MR]);     // index 1 stores the address of A
                        // scratchpad_write(3, _C);     // index 3 stores the address of AB
                        // scratchpad_write(5, 4);   // integer of size 4 byte
                        // scratchpad_write(2, &_B[j*kc*NR+_kc*NR]); // index 2 stores the upper bound
                        scratchpad_write(7, 0);
                        scratchpad_write(2, &B[(j+1)*kc*NR]);

                        dgemm_micro_kernel();

                        int a, b;
                        Dtype* _C = &C[i*MR*incRowC+j*NR];
                        for (a=0; a<nr; ++a) {
                            for (b=0; b<mr; ++b) {
                                _C[b*incRowC+a] += scratchpad_read(b+a*MR);
                            }
                        }
            }
        }
    }
}

typedef struct global_data_ {
  int m;
  int n;
  int k;
  Dtype  *C;
  Dtype *B;
  Dtype *A;
  int     incRowC;
  int     incColC;
  int     incRowB;
  int     incColB;
  int     incRowA;
  int     incColA;
  int cores;
} global_data;


//
//  Compute C <- beta*C + A*B
//
void
dgemm_nn_worker(
         const void* data1)
{
    global_data* data = (global_data*)data1;
    int m = data->m;
    int n = data->n;
    int k = data->k;
    Dtype* A = data->A;
    Dtype* B = data->B;
    Dtype* C = data->C;
    int incRowA = data->incRowA;
    int incRowB = data->incRowB;
    int incRowC = data->incRowC;
    int incColA = data->incColA;
    int incColB = data->incColB;
    int incColC = data->incColC;

    int core = get_core_id();
    int addr = loki_mem_address(0, core, CH_REGISTER_3, GROUPSIZE_8, false, false, false, false);  
    set_channel_map(2, addr);

    int mb = (m+MC-1) / MC;
    int nb = (n+NC-1) / NC;
    int kb = (k+KC-1) / KC;

    int _mc = m % MC;
    int _nc = n % NC;
    int _kc = k % KC;

    int mc, nc, kc;
    int i, j, l;


    for (j=0; j<nb; ++j) {
        nc = (j!=nb-1 || _nc==0) ? NC : _nc;
        for (l=0; l<kb; ++l) {
            kc    = (l!=kb-1 || _kc==0) ? KC   : _kc;

            // unsigned long cycle_count = get_cycle_count();            
            if(core == 0)
              pack_B(kc, nc,
                   &B[l*KC*incRowB+j*NC*incColB], 
                   incRowB, incColB,
                   _B);
            loki_sync(MATRIX_NUM_CORE);

            // cycle_count = get_cycle_count() - cycle_count;

            // fprintf(stderr, "takes %lu cycle to complete packB with kc \n", cycle_count);


            for (i=0; i<mb; ++i) {
                mc = (i!=mb-1 || _mc==0) ? MC : _mc;
                
                  // core 0 transpose and pack the value
                  if(core == 0){
                    pack_A(mc, kc,
                           &A[i*MC*incRowA+l*KC*incColA], incRowA, incColA,
                           _A);
                    // fprintf(stderr, "\n");
                  }
                  loki_sync(MATRIX_NUM_CORE);
                  dgemm_macro_kernel(mc, nc, kc,
                                     &C[i*MC*incRowC+j*NC],
                                     _B,
                                     _A,
                                     incRowC);
            }
        }
    }
    loki_sync(MATRIX_NUM_CORE);

}

void
dgemm_nn(int            m,
         int            n,
         int            k,
         const Dtype   *A,
         int            incRowA,
         // int            incColA,
         const Dtype   *B,
         int            incRowB,
         // int            incColB,
         // Dtype         beta,
         Dtype         *C,
         int            incRowC
         // int            incColC
         ){

                  loki_init_default(MATRIX_NUM_CORE, 0);
                  global_data* data = malloc(sizeof(global_data));
                  data->m = m;
                  data->n = n;
                  data->k = k;
                  data->C = C;
                  data->B = B;
                  data->A = A;
                  data->incRowA = incRowA;
                  data->incColA = 1;
                  data->incRowB = incRowB;
                  data->incColB = 1;
                  data->incRowC = incRowC;
                  data->incColC = 1;
                  data->cores = MATRIX_NUM_CORE;
                  
                  distributed_func* config = malloc(sizeof(distributed_func));
                  config->cores = MATRIX_NUM_CORE;
                  // set the function to be macro_kernel
                  config->func = &dgemm_nn_worker;
                  config->data = data;
                  config->data_size = sizeof(global_data);
                  loki_execute(config);
}