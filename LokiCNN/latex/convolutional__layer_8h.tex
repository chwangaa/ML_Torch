\hypertarget{convolutional__layer_8h}{}\section{src/convolutional\+\_\+layer.h File Reference}
\label{convolutional__layer_8h}\index{src/convolutional\+\_\+layer.\+h@{src/convolutional\+\_\+layer.\+h}}


G\+E\+MM version of convolutional layer.  


{\ttfamily \#include \char`\"{}layer.\+h\char`\"{}}\\*
{\ttfamily \#include \char`\"{}math\+\_\+functions.\+h\char`\"{}}\\*
\subsection*{Typedefs}
\begin{DoxyCompactItemize}
\item 
typedef \hyperlink{structLayer}{Layer} \hyperlink{convolutional__layer_8h_a9b6de429dd995cf6d499f1e9545910b5}{conv\+\_\+layer\+\_\+t}
\end{DoxyCompactItemize}
\subsection*{Functions}
\begin{DoxyCompactItemize}
\item 
void \hyperlink{convolutional__layer_8h_a6e69af0d82693367407b34385a25955b}{conv\+\_\+forward} (const \hyperlink{convolutional__layer_8h_a9b6de429dd995cf6d499f1e9545910b5}{conv\+\_\+layer\+\_\+t} $\ast$l, const \hyperlink{data__structure_8h_a051bd2b17d42e70d86b4314e0dd8881e}{vol\+\_\+t} $\ast$$\ast$\hyperlink{max__pooling__layer__MultiCore_8h_ab943d53559ea6283e896bd8bf603b626}{in}, \hyperlink{data__structure_8h_a051bd2b17d42e70d86b4314e0dd8881e}{vol\+\_\+t} $\ast$$\ast$\hyperlink{max__pooling__layer__MultiCore_8h_abc600ae3097d3509f83258671cf3701e}{out}, const int \hyperlink{max__pooling__layer__MultiCore_8h_a79cb7003c3528d3096592502cbd07fb9}{start}, const int \hyperlink{max__pooling__layer__MultiCore_8h_a3efd06bf9a5c88624e60c85040903747}{end})
\begin{DoxyCompactList}\small\item\em conv layer forward routine \end{DoxyCompactList}\item 
\hyperlink{convolutional__layer_8h_a9b6de429dd995cf6d499f1e9545910b5}{conv\+\_\+layer\+\_\+t} $\ast$ \hyperlink{convolutional__layer_8h_a2f87b735bc9ecbad728dcb06f4d46fcd}{make\+\_\+conv\+\_\+layer} (int in\+\_\+sx, int in\+\_\+sy, int in\+\_\+depth, int sx, int filters, int stride, int pad)
\begin{DoxyCompactList}\small\item\em constructor of convolutional layer \end{DoxyCompactList}\item 
void \hyperlink{convolutional__layer_8h_a7c2f2ea6b02d96d6324900844d4e535e}{conv\+\_\+load} (\hyperlink{convolutional__layer_8h_a9b6de429dd995cf6d499f1e9545910b5}{conv\+\_\+layer\+\_\+t} $\ast$l, const int $\ast$params, const \hyperlink{setting_8h_ac7889bf9b3596f63c57011af217212dd}{weight\+\_\+t} $\ast$weights)
\begin{DoxyCompactList}\small\item\em default convolutional layer weight loader \end{DoxyCompactList}\end{DoxyCompactItemize}


\subsection{Detailed Description}
G\+E\+MM version of convolutional layer. 



\subsection{Typedef Documentation}
\index{convolutional\+\_\+layer.\+h@{convolutional\+\_\+layer.\+h}!conv\+\_\+layer\+\_\+t@{conv\+\_\+layer\+\_\+t}}
\index{conv\+\_\+layer\+\_\+t@{conv\+\_\+layer\+\_\+t}!convolutional\+\_\+layer.\+h@{convolutional\+\_\+layer.\+h}}
\subsubsection[{conv\+\_\+layer\+\_\+t}]{\setlength{\rightskip}{0pt plus 5cm}typedef {\bf Layer} {\bf conv\+\_\+layer\+\_\+t}}\hypertarget{convolutional__layer_8h_a9b6de429dd995cf6d499f1e9545910b5}{}\label{convolutional__layer_8h_a9b6de429dd995cf6d499f1e9545910b5}


\subsection{Function Documentation}
\index{convolutional\+\_\+layer.\+h@{convolutional\+\_\+layer.\+h}!conv\+\_\+forward@{conv\+\_\+forward}}
\index{conv\+\_\+forward@{conv\+\_\+forward}!convolutional\+\_\+layer.\+h@{convolutional\+\_\+layer.\+h}}
\subsubsection[{conv\+\_\+forward(const conv\+\_\+layer\+\_\+t $\ast$l, const vol\+\_\+t $\ast$$\ast$in, vol\+\_\+t $\ast$$\ast$out, const int start, const int end)}]{\setlength{\rightskip}{0pt plus 5cm}void conv\+\_\+forward (
\begin{DoxyParamCaption}
\item[{const {\bf conv\+\_\+layer\+\_\+t} $\ast$}]{l, }
\item[{const {\bf vol\+\_\+t} $\ast$$\ast$}]{in, }
\item[{{\bf vol\+\_\+t} $\ast$$\ast$}]{out, }
\item[{const int}]{start, }
\item[{const int}]{end}
\end{DoxyParamCaption}
)}\hypertarget{convolutional__layer_8h_a6e69af0d82693367407b34385a25955b}{}\label{convolutional__layer_8h_a6e69af0d82693367407b34385a25955b}


conv layer forward routine 


\begin{DoxyParams}{Parameters}
{\em l} & the layer, internally defines convolution parameters like kernel size, padding size, etc. \\
\hline
{\em in} & the input images \\
\hline
{\em out} & the ouput images \\
\hline
{\em start} & the index in the input batch from which to perform forwarding \\
\hline
{\em end} & the index in the input batch from which to stop perform forwarding\\
\hline
\end{DoxyParams}
start and end helps to define the batch size, i.\+e. batch\+\_\+size = end-\/start. They are useful as one can flexibly decides whether to load a lot of batches into main memory and use indices to define batch size. And even variable batch\+\_\+size is possible with changing values of start and end \index{convolutional\+\_\+layer.\+h@{convolutional\+\_\+layer.\+h}!conv\+\_\+load@{conv\+\_\+load}}
\index{conv\+\_\+load@{conv\+\_\+load}!convolutional\+\_\+layer.\+h@{convolutional\+\_\+layer.\+h}}
\subsubsection[{conv\+\_\+load(conv\+\_\+layer\+\_\+t $\ast$l, const int $\ast$params, const weight\+\_\+t $\ast$weights)}]{\setlength{\rightskip}{0pt plus 5cm}void conv\+\_\+load (
\begin{DoxyParamCaption}
\item[{{\bf conv\+\_\+layer\+\_\+t} $\ast$}]{l, }
\item[{const int $\ast$}]{params, }
\item[{const {\bf weight\+\_\+t} $\ast$}]{weights}
\end{DoxyParamCaption}
)}\hypertarget{convolutional__layer_8h_a7c2f2ea6b02d96d6324900844d4e535e}{}\label{convolutional__layer_8h_a7c2f2ea6b02d96d6324900844d4e535e}


default convolutional layer weight loader 


\begin{DoxyParams}{Parameters}
{\em l} & pointer to the convolutional layer \\
\hline
{\em params} & specifiers of convolutional layer parameters, used to track whether the weight file matches the convolutional layer\textquotesingle{}s requirement \\
\hline
{\em weights} & pointer to the starting point of weight array\\
\hline
\end{DoxyParams}
this is just one way of loading values, one can easily define its own loader according to specific needs for loading from weights trained by caffe, this is an easy approach \index{convolutional\+\_\+layer.\+h@{convolutional\+\_\+layer.\+h}!make\+\_\+conv\+\_\+layer@{make\+\_\+conv\+\_\+layer}}
\index{make\+\_\+conv\+\_\+layer@{make\+\_\+conv\+\_\+layer}!convolutional\+\_\+layer.\+h@{convolutional\+\_\+layer.\+h}}
\subsubsection[{make\+\_\+conv\+\_\+layer(int in\+\_\+sx, int in\+\_\+sy, int in\+\_\+depth, int sx, int filters, int stride, int pad)}]{\setlength{\rightskip}{0pt plus 5cm}{\bf conv\+\_\+layer\+\_\+t}$\ast$ make\+\_\+conv\+\_\+layer (
\begin{DoxyParamCaption}
\item[{int}]{in\+\_\+sx, }
\item[{int}]{in\+\_\+sy, }
\item[{int}]{in\+\_\+depth, }
\item[{int}]{sx, }
\item[{int}]{filters, }
\item[{int}]{stride, }
\item[{int}]{pad}
\end{DoxyParamCaption}
)}\hypertarget{convolutional__layer_8h_a2f87b735bc9ecbad728dcb06f4d46fcd}{}\label{convolutional__layer_8h_a2f87b735bc9ecbad728dcb06f4d46fcd}


constructor of convolutional layer 


\begin{DoxyParams}{Parameters}
{\em in\+\_\+sx} & the width of input image \\
\hline
{\em in\+\_\+sy} & the height of input image \\
\hline
{\em in\+\_\+depth} & the channel number of input image \\
\hline
{\em sx} & the width of convolution kernel, note the kernel must be square \\
\hline
{\em filters} & the number of output images, this means the total weight size is filters$\ast$sx$\ast$sx \\
\hline
{\em stride} & the number of pixels between consecutive convolutional kernel movement, usually 1 \\
\hline
{\em pad} & the number of 0 paddings to add to the input image before applying convolutions \\
\hline
\end{DoxyParams}
for Loki\+C\+NN, it is required that kernel width == kernel height

the images are stored in one dimension flat arrays 